% optimization documentation
\section{optim (optimization)}
Newton-raphson, gradient, evolutionary algorithms, etc.

\subsection{Gradient search}
This module implements a gradient or ``steepest-descent'' search.
Given a function $f$ which operates on a vector
$\vec{x} = [x_0,x_1,\ldots,x_{N-1}]^T$ of $N$ parameters,
the gradient search method seeks to find the optimum $\vec{x}$ which
minimizes $f(\vec{x})$.

\subsubsection{Theory}
The gradient search is an iterative method, and adjusts $\vec{x}$ proportional
to the negative of the gradient of $f$ evaluated at the current location.
The vector $\vec{x}$ is adjusted by
\[
    \Delta \vec{x}[n+1] = -\gamma[n] \nabla f(\vec{x}[n])
\]
where $\gamma[n]$ is the step size and
$\nabla f(\vec{x}[n])$ is the gradient of $f$ at $\vec{x}$, at the $n^{th}$
iteration.
The gradient is a vector field which points to the greatest rate of increase,
and is computed at $\vec{x}$ as
\[
    \nabla f(\vec{x}) = \left(
        \frac{\partial f}{\partial x_0},
        \frac{\partial f}{\partial x_1},
        \ldots,
        \frac{\partial f}{\partial x_{N-1}}
    \right)
\]
In most non-linear optimization problems, $\nabla f(\vec{x})$ is not known,
and must be approximated for each value of $\vec{x}[n]$ using the finite element
method.
The partial derivative of the $k^{th}$ component is estimated by computing the
slope of $f$ when $x_k$ is increased by a small amount $\Delta$ while holding
all other elements of $\vec{x}$ constant.
This process is repeated for all elements in $\vec{x}$ to comput the gradient
vector.
Mathematically, the $k^{th}$ component of the gradient is approximated by
\[
    \frac{\partial f(\vec{x})}{\partial x_k} \approx 
    \frac{f(x_0,\ldots,x_k+\Delta,\ldots,x_{N-1}) - f(\vec{x})}{\Delta}
\]
Once $\nabla f(\vec{x}[n])$ is known, $\Delta\vec{x}[n+1]$ is computed and the
optimizing vector is updated via
\[
    \vec{x}[n+1] = \vec{x}[n] + \Delta\vec{x}[n+1]
\]

\subsubsection{Momentum constant}
When $f(\vec{x})$ is flat (i.e. $\nabla f(\vec{x})\approx \vec{0}$),
convergence will be slow.
This effect can be mitigated by permitting the update vector equation to
retain a small portion of the previous step vector.
The updated vector at time $n+1$ is
\[
    \vec{x}[n+1] = \vec{x}[n] + \Delta\vec{x}[n+1] + \alpha\Delta\vec{x}[n]
\]
where $\Delta\vec{x}[0] = \vec{0}$.
The update...
\[
    \vec{x}[n+1] = 
        %\Delta\vec{x}[n+1] +
        \sum_{k=0}^{n+1}{\alpha^{k}\Delta\vec{x}[n+1-k]}
\]
which is stable only for $0 \le \alpha < 1$.
For flat regions, the gradient vector $\nabla f(\vec{x})$ is approximately a
constant $\Delta\vec{x}$, and $\vec{x}[n]$ therefore becomes a geometric
series converging to $\Delta\vec{x}/(1-\alpha)$.
This accelerates the algorithm across relatively flat regions of $f$.
The momentum constant additionally adds some stability for regions where the
gradient method tends to oscillate, such as steep valleys in $f$.

\subsubsection{Step size adjustment}
In \liquid, the gradient is normalized to unity (orthonormal).
That is $\|\nabla f(\vec{x}[n])\|=1$.
Furthermore, $\gamma$ is slightly reduced each epoch by a multiplier $\mu$
\[
    \gamma[n+1] = \mu \gamma[n]
\]
This helps improve stability and convergence over regions where the algorithm
might oscillate due to steep values of $f$.
%The default value for $\mu$ is 0.99.

\subsubsection{Usage}
Here is a summary of the parameters used in the gradient search algorithm and
their default values:
\begin{itemize}
\item[$\Delta$] : step size in computing the gradient (default $10^{-6}$)
\item[$\gamma$] : step size in updating $\vec{x}[n]$ (default 0.002)
\item[$\alpha$] : momentum constant (default 0.1)
\item[$\mu$]    : iterative $\gamma$ adjustment factor (default 0.99)
\end{itemize}

Here is an example of how the {\tt gradient\_search} is used:
% gradient_search example
\input{listings/gradient_search.example.c.tex}


