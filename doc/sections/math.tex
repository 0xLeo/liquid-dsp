% 
% MODULE : math
%

\section{math}
\label{module:math}
transcendental functions not in the C standard library (gamma, besseli, etc.)
and polynomial operations

{\tt liquid\_lngammaf}
\[
    \ln(\Gamma(z)) \approx
    \frac{z}{2} \ln\left( \frac{2\pi}{z} \right)
    \left(
        \ln\left(z + \frac{1}{12 z - 0.1/z} \right) - 1
    \right)
\]

{\tt liquid\_sincf}
\[ \sinc(z) = \frac{\sin(\pi z)}{\pi z} \]
For small $z$, this can be approximated by expanding the first few terms of
the series
\[
    \sinc(z) = \prod_{k=1}^{\infty}{ \cos\left( 2^{-k} \pi z \right) }
\]

{\tt liquid\_besseli0}
\[
    \ln\Bigl[\ln\left(I_0(z)\right)\Bigr] \approx
    c_0 + c_1 t + c_2 t ^2 + c_3 t^3
\]
where $t=\ln(z)$ and
\[
    \left\{c_0,c_1,c_2,c_3\right\} =
    \begin{cases}
    \left\{\text{-1.52624, 1.9597, -9.4287e-03, -7.0471e-04}\right\} & t < 0.5 \\
    \left\{\text{-1.5531, 1.8936, -0.07972, -0.01333}\right\} & 0.5 \le t < 2.3 \\
    \left\{\text{-1.2958, 1.7693, -0.1175, 0.006341}\right\} & \text{else}.
    \end{cases}
\]
This is a particularly useful approximation for the Kaiser window in
fixed-point math where $w[n]$ is computed as the ratio of two large numbers.

An iterative method comes from Gross(1995),
%\cite{Gross:1995}
\[
    I_\nu(z) = \sum_{k=0}^{\infty}{\frac{\left(\frac{1}{4}z^2\right)^k}{k!\Gamma(k+\nu+1)}}
\]

{\tt liquid\_nchoosek()}
\[
    {n \choose k} = \frac{n!}{(n-k)!k!}
\]

{\tt liquid\_nextpow2()} computes $\lceil \log_2(x) \rceil$

\subsection{Windowing functions}
Kaiser, Hamming, Hann, Blackman-harris

\subsection{Polynomials}
A number of \liquid\ modules require polynomial manipulations, particularly
those involving filter design where transfer functions are represented as the
explicit ratio of polynomials in $z^{-1}$.
This sub-module is not intended to be complete, but rather is required for
the proper functionality of other modules.
Like matrices, polynomials in \liquid\ do not use a particular data type, but
are stored as memory arrays.
\[
    P_n(x) = \sum_{k=0}^{n}{c_k x^k}
           = c_0 + c_1 x + c_2 x^2 + \cdots + c_n x^n
\]
An $n^{th}$-order polynomial has $n+1$ coefficients ordered in memory in
increasing degree.
For example, a $2^{nd}$-order polynomial $0.1 -2.4x + 1.3x^2$ stored in an
array {\tt float c[]} has
{\tt c[0]=0.1},
{\tt c[1]=-2.4}, and
{\tt c[2]=1.3}.%
\footnote{Note that this convention is reversed from that used in octave
[cite:octave:web].}

\subsubsection{{\tt polyval()}}
Evaluates the polynomial $P_n(x)$ at $x_0$.

\subsubsection{{\tt polyfit()}}
Fits data to a polynomial of order $k-1$ from $n$ samples using the
least-squares method.
Data vectors
$\vec{x}=[x_0,x_1,\cdots,x_{n-1}]^T$ and 
$\vec{y}=[y_0,y_1,\cdots,y_{n-1}]^T$...
Uses matrix algebra to solve system of equations...
\[
    \vec{p} = \left(\vec{X}^T\vec{X}\right)^{-1}\vec{X}^T\vec{y}
\]
where
\[
    \vec{X} = 
    \begin{bmatrix}
        1   & x_0       & x_0^2     & \cdots    & x_0^{k}     \\
        1   & x_1       & x_1^2     & \cdots    & x_1^{k}     \\
        \\
        1   & x_{n-1}   & x_{n-1}^2 & \cdots    & x_{n-1}^{k}
    \end{bmatrix}
\]


\subsubsection{{\tt polyfit\_lagrange()}}
Fits dataset of $n$ sample points to exact polynomial of order $n-1$ using
Lagrange interpolation.
Given input vectors
$\vec{x}=[x_0,x_1,\cdots,x_{n-1}]^T$ and 
$\vec{y}=[y_0,y_1,\cdots,y_{n-1}]^T$, the interpolating polynomial is
\[
    P_{n-1}(x) =
        \sum_{j=0}^{n-1} {
            \left[
            y_j
            \prod_{{k=0}\atop{k \ne j}}^{n-1} {
                \frac{x-x_k}{x_j-x_k}
            }
            \right]
        }
\]
See also {\tt poly\_expandroots}.

\subsubsection{{\tt poly\_interp\_lagrange()}}
Uses Lagrange polynomials to find the interpolant
$(\dot{x},\dot{y})$ from a set of $n$ pairs
$\vec{x}=[x_0,x_1,\cdots,x_{n-1}]^T$ and 
$\vec{y}=[y_0,y_1,\cdots,y_{n-1}]^T$.
\[
    \dot{y} =
        \sum_{j=0}^{n-1} {
            \left[
            y_j
            \prod_{{k=0}\atop{k \ne j}}^{n-1} {
                \frac{\dot{x}-x_k}{x_j-x_k}
            }
            \right]
        }
\]
See also {\tt polyfit\_lagrange()}.

\subsubsection{{\tt polyfit\_lagrange\_barycentric()}}
Computes the barycentric weights $\vec{w}$ of $\vec{x}$ via
\[
    w_j =   \frac{1}{
                \prod_{k \ne j}{\left(x_j - x_k\right)}
            }
\]
which can be used to compute the interpolant $(\dot{x},\dot{y})$ as
\[
    \dot{y} =   \frac{
                    \sum\limits_{j=0}^{k-1}{ w_j y_j /(\dot{x}-x_j) }
                } {
                    \sum\limits_{j=0}^{k-1}{     w_j /(\dot{x}-x_j) }
                }
\]
This is the preferred method for computing Lagrange interpolating polynomials,
particularly if $\vec{x}$ is unchanging.
The function returns $\dot{y}$ if $\dot{x}$ is equal to any $x_j$.

\subsubsection{{\tt poly\_expandroots()}}
Expands the a polynomial based on its roots
\[
    P_n(x) = \prod_{k=0}^{n-1}{(x+a_k)}
\]
where $r_k=-a_k$ are the roots of $P_n(x)$.

\subsubsection{{\tt poly\_expandroots2()} {\it not implemented}}
Expands the a polynomial as
\[
    P_n(x) = \prod_{k=0}^{n-1}{(b_kx+a_k)}
\]

\subsubsection{{\tt poly\_binomial\_expand()}}
Expands the a polynomial as a binomial series
\[
    P_n(x) = (x+1)^n = \sum_{k=0}^{n}{ {n \choose k} x^k}
\]

\subsubsection{{\tt poly\_binomial\_expand\_pm()}}
Expands the a polynomial as an alternating binomial series
[NOTE: change terminology?]
\[
    P_n(x) = (x+1)^j (x-1)^{n-j}
           = \left( \sum_{k=0}^{j}  { {n \choose k}    x^k} \right)
             \left( \sum_{k=0}^{n-j}{ {n \choose k} (-x)^k} \right)
\]

\subsubsection{{\tt polymul()}}
Multiplies two polynomials $P_n(x)$ and $Q_m(x)$.

\subsubsection{{\tt polydiff()} {\it not yet implemented}}
Computes the derivative $\frac{\partial}{\partial x}P_n(x)$ of polynomial
$P_n(x)$
\[
    \frac{\partial}{\partial x}P_n(x) = \sum_{k=1}^{n}{c_{k}x^{k-1}}
\]

\subsubsection{{\tt poly\_findroots\_bairstow()}}
Finds the $n$ roots of the $n^{th}$-order polynomial using Bairstow's method.
For a polynomial $P_n(x)$...
\[
    P_n(x) = \prod_{k=0}^{n-1}{(x-r_k)}
\]
...there exists a polynomial $p_{2}(x)=u + vx + x^2$ which divides
$P_{n}(x)$ exactly and has two roots (possibly complex)
\[
    r_0 = \frac{1}{2}\left(-v-\sqrt{v^2-4u}\right), \; \\
    r_1 = \frac{1}{2}\left(-v+\sqrt{v^2-4u}\right)
\]
If indeed the roots $r_0$ and $r_1$ are complex, they are also complex
conjugates.
Bairstow's method uses Newtonian iterations to find a pair $u$ and $v$ which
are both finite and real-valued.
This method has several advantages over other methods
\begin{itemize}
\item iterations operate on real-valued math, even if the roots are complex
\item the algorithm is capable of handling multiple roots (unlike the
      Durand-Kerner method)
\item the algorithm does not rely on expanding the full polynomial and is
      therefore resilient to machine precision
\end{itemize}


